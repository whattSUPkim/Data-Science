{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bae4137a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae2490d",
   "metadata": {},
   "source": [
    "# 텐서플로"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3173f991",
   "metadata": {},
   "source": [
    "## 텐서플로(Tensorflow)\n",
    "- 구글이 만든 딥러닝 오픈소스 패키지\n",
    "    - 머신러닝 알고리즘을 구현하고 실행하기 위한 프로그램이 인터페이스\n",
    "- 텐서플로 특징\n",
    "    - 확장이 용이하고 다양한 플랫폼을 지원\n",
    "    - 강력한 수치 계산용 라이브러리\n",
    "    - **분산 컴퓨팅 지원**\n",
    "    - 계산 그래프를 사용하여 계산을 최적화\n",
    "        - 사용하지 않는 노드의 가지치키\n",
    "        - 독립적 연산은 병렬 실행\n",
    "    - 자동 미분 기능, 고성능 옵티마이저 제공\n",
    "- 가장 인기있는 딥러닝 라이브러리 : 대규모 머신러닝에 적합\n",
    "- 머신러닝 작업 속도가 매우 빠름\n",
    "    - CPU와 GPU(CUDA 기반)를 사용\n",
    "    - GPU 사용 : 그래픅 카드를 작은 컴퓨터 클러스터로 생각\n",
    "        - 계산을 작은 단위로 나눠 여러 GPU 스레드에서 병렬로 실행\n",
    "        - 파이썬의 GIL로 하나의 코어만 사용하는 문제를 해결하여 대용량 데이터 처리 가능\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d64fce5",
   "metadata": {},
   "source": [
    "## 텐서플로 파이썬 API\n",
    "|종류|모듈(패키지)|\n",
    "|--|--|\n",
    "|고수준 딥러닝 API|`tf.keras`, `tf.estimator`|\n",
    "|저수준 딥러닝 API|`tf.nn`, `tf.losses`, `tf.metrics`, `tf.optimizers`, `tf.train`, `tf.initializers`|\n",
    "|입출력과 전처리|`tf.data`, `tf.io`, `tf.image`|\n",
    "|선형대수와 신호처리|`tf.math`, `tf.linalg`, `tf.signal`, `tf.random`|\n",
    "|자동 미분|`tf.GradientTape`, `tf.gradients`|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0835e6c0",
   "metadata": {},
   "source": [
    "# 텐서"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6f9951",
   "metadata": {},
   "source": [
    "## 텐서(tensor)\n",
    "- 넘파이 다차원 배열(ndarray)과 유사\n",
    "- 계산 그래프의 각 노드는 입력과 출력을 갖는 연산으로 표현되며, 이런 연산의 입력과 출력을 참조하기 위한 심볼릭 핸들(symbilc handle) 역할을 함\n",
    "- **실제 값은 넘파이 배열이고, 텐서는 배열에 대한 참조를 제공**\n",
    "    - 텐서가 참조하는 값 : 텐서.numpy() 메서드 혹은 np.array(텐서)\n",
    "- 텐서 만들기\n",
    "    - `tf.convert_to_tenser()` : 리스트나 넘파이 배열로부터 텐서 생성\n",
    "        - 부동소수 : 텐서는 32-bit, 넘파이 배열은 64-bit\n",
    "    - `tf.constant()` : 변경 불가능(immutable)한 텐서 객체 생성\n",
    "    - `tf.Variable()` : 변경가능한 텐서 객체 생성(ex. 신경망의 가중치들)\n",
    "        - `assign()`으로 값 수정\n",
    "- 텐서 속성 : shape, dtype\n",
    "- 인덱스 참조 : 넘파이 배열과 유사\n",
    "- 텐서 연산\n",
    "    - +, -, *, @\n",
    "    - `tf.add`, `tf.multiply`, `tf.square`, `tf.sqrt`, `tf.reshape`, `tf.reduce_mean`, `tf.math.log`, ...\n",
    "    - 넘파이 배열과 텐서의 연산은 호환성을 가짐\n",
    "- 텐서 형변환 : `tf.cast(텐서, dtype)`\n",
    "    - (텐서는 형에 예민함)\n",
    "- 텐서 모양 변경 : `tf.reshape(텐서, shape)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9b83b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = tf.convert_to_tensor(10)  # 스칼라, rank = 0 (0차원)\n",
    "t1 = tf.convert_to_tensor([1, 2, 4.0])  # rank = 1 (1차원)\n",
    "t2 = tf.Variable([[1, 2, 3], [4, 5, 6]])  # rank = 2,  (dtype = int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96187403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=10>,\n",
       " <tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 2., 4.], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(2, 3) dtype=int32, numpy=\n",
       " array([[1, 2, 3],\n",
       "        [4, 5, 6]])>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0, t1, t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbfbfd4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=int32, numpy=\n",
       "array([[  1,   2,   3],\n",
       "       [  4, 100,   6]])>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign()\n",
    "t2[1, 1].assign(100)\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ed341c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[  1.,   2.,   3.],\n",
       "       [  4., 100.,   6.]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 형변환\n",
    "t2_float = tf.cast(t2, dtype = tf.float32)\n",
    "t2_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "514ac6ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([100.,   6.], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인덱싱\n",
    "t2_float[1, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f1c353b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[  2.,   4.,   7.],\n",
       "       [  5., 102.,  10.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 + t2_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e227a560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=int32, numpy=array([  1,   2,   3,   4, 100,   6])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape\n",
    "t2_reshape = tf.reshape(t2, shape = (6,))\n",
    "t2_reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828b9beb",
   "metadata": {},
   "source": [
    "- 텐서 분할 / 쌓기 / 연결 : `split()`/`stack()`/`concat()` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20905ce7",
   "metadata": {},
   "source": [
    "# 텐서플로 데이터셋 API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b4f84a",
   "metadata": {},
   "source": [
    "## 텐서플로 데이터셋 API(tf.data)  \n",
    "(= tensor들의 collection)\n",
    "- 데이터셋이 메모리에 충분히 적재 가능한 경우 : 텐서를 바로 사용\n",
    "- 데이터셋이 메모리보다 큰 경우 : 배치(batch) 단위로 적재\n",
    "- `tf.data.Dataset.from_tensor_slices()`\n",
    "    - 리스트, 넘파이 배열, 텐서에 대하여 Dataset 객체를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccc1ea85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (), types: tf.int32>\n",
      "\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices(np.arange(5))\n",
    "print(ds)  # dataset 정보\n",
    "print()\n",
    "for ex in ds:\n",
    "    print(ex)  # 텐서별로 보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc17290",
   "metadata": {},
   "source": [
    "## 신경망 입력을 위한 텐서플로 데이터셋 만들기\n",
    "- 두 개의 텐서를 하나의 데이터셋으로 연결하기 : `zip()` 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c31372d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.3, 0.5], dtype=float32)>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n",
      "(<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.8, 0.4], dtype=float32)>, <tf.Tensor: shape=(), dtype=int32, numpy=1>)\n",
      "(<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.1 , 0.75], dtype=float32)>, <tf.Tensor: shape=(), dtype=int32, numpy=2>)\n",
      "\n",
      "[0.3 0.5] 0\n",
      "[0.8 0.4] 1\n",
      "[0.1  0.75] 2\n"
     ]
    }
   ],
   "source": [
    "d_x = tf.data.Dataset.from_tensor_slices([[0.3, 0.5], [0.8, 0.4], [0.1, 0.75]])  # X\n",
    "d_y = tf.data.Dataset.from_tensor_slices([0, 1, 2])  # y\n",
    "ds_joint = tf.data.Dataset.zip((d_x, d_y))\n",
    "\n",
    "for ex in ds_joint:\n",
    "    print(ex)\n",
    "print()\n",
    "for ex in ds_joint:\n",
    "    print(ex[0].numpy(), ex[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95b3305",
   "metadata": {},
   "source": [
    "- Dataset의 각 원소에 변환 적용하기 : `map()` 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9f5fe54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.39999998  0.        ] 0\n",
      "[ 0.6        -0.19999999] 1\n",
      "[-0.8  0.5] 2\n"
     ]
    }
   ],
   "source": [
    "ds_map = ds_joint.map(lambda x, y : (2 * x-1, y))\n",
    "for ex in ds_map:\n",
    "    print(ex[0].numpy(), ex[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a7f84e",
   "metadata": {},
   "source": [
    "- 신경망 모델을 훈련하기 위해서는 훈련 데이터를 무작위로 섞은 배치로 만들어 주입해야 함\n",
    "- Dataset 객체 섞기 : `shuffle()` 메서드\n",
    "    - buffer_size 인수 : 완벽한 셔플링을 위해서는 데이터 세트의 전체 크기보다 크거나 같은 버퍼 크기가 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "791c1a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(2,), dtype=float32, numpy=array([-0.39999998,  0.        ], dtype=float32)>> 0\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(2,), dtype=float32, numpy=array([-0.8,  0.5], dtype=float32)>> 2\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 0.6       , -0.19999999], dtype=float32)>> 1\n"
     ]
    }
   ],
   "source": [
    "ds_ = ds_map.shuffle(buffer_size = 100)\n",
    "for ex in ds:\n",
    "    print(ex[0].numpy, ex[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26518de",
   "metadata": {},
   "source": [
    "- Dataset 객체 원소의 배치 만들기 : batch() 메서드\n",
    "    - batch_size 인수 : 배치 크기\n",
    "    - drop_remainder(= False) : True면, 배치의 크기보다 작은 배치(남은 데이터)는 버림  # default = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a68aa6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.8         0.5       ]\n",
      " [ 0.6        -0.19999999]] [2 1]\n",
      "[[-0.39999998  0.        ]] [0]\n"
     ]
    }
   ],
   "source": [
    "ds_batch = ds.batch(batch_size = 2)\n",
    "for ex in ds_batch:\n",
    "    print(ex[0].numpy(), ex[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4f7a48",
   "metadata": {},
   "source": [
    "## 로컬 디스크에 있는 파일들로부터 데이터셋 만들기\n",
    "- 이미지 파일 : tf.io, tf.image 모듈 사용\n",
    "- 이미지 파일과 레이블로 이루어진 Dataset 만든 후, map() 메서드를 사용하여 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14547a9d",
   "metadata": {},
   "source": [
    "## tensorflow_datasets 라이브러리 데이터셋 로드\n",
    "- `import tensorflow_datasets as tfds`\n",
    "- 방법1 : `builder()` -> `download_and_prepare()` -> `as_dataset()`\n",
    "- 방법2 : `load()`함수 (wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5d20ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\user\\tensorflow_datasets\\iris\\2.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e3092ea21d4cd4bdecdbffa0ba068c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ffb92fb6b544e6884f273cea0567136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling iris-train.tfrecord...:   0%|          | 0/150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset iris downloaded and prepared to C:\\Users\\user\\tensorflow_datasets\\iris\\2.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 아이리스 데이터셋 만들기\n",
    "import tensorflow_datasets as tfds\n",
    "iris = tfds.load('iris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "491fc7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Split('train'): <PrefetchDataset shapes: {features: (4,), label: ()}, types: {features: tf.float32, label: tf.int64}>}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23db87cf",
   "metadata": {},
   "source": [
    "- iris Dataset은 'train'을 키로 하는 한 덩어리이므로, 실제 훈련용과 테스트용으로 분할해야 함\n",
    "- 각 원소는 features와 label을 키로 하는 닥셔너리 형태임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e1615905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TakeDataset shapes: {features: (4,), label: ()}, types: {features: tf.float32, label: tf.int64}>\n",
      "<SkipDataset shapes: {features: (4,), label: ()}, types: {features: tf.float32, label: tf.int64}>\n"
     ]
    }
   ],
   "source": [
    "ds = iris['train']\n",
    "ds = ds.shuffle(buffer_size = 150, reshuffle_each_iteration = False)\n",
    "\n",
    "ds_train = ds.take(100)  # 훈련용 100개\n",
    "ds_test = ds.skip(100)  # 테스트용 100개를 뺸 나머지\n",
    "print(ds_train)\n",
    "print(ds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2209418",
   "metadata": {},
   "source": [
    "- map() 메서드를 이용하여 딕셔너리를 튜플로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5304c7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_train.map(lambda x : (x['features'], x['label']))\n",
    "ds_test = ds_test.map(lambda x : (x['features'], x['label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c9c331",
   "metadata": {},
   "source": [
    "- 아이리스 MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "92dd1964",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_mlp = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(16, input_shape = (4,), activation = 'sigmoid'),\n",
    "    tf.keras.layers.Dense(3, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c0c17cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_mlp.compile(optimizer = 'adam',\n",
    "                 loss = 'sparse_categorical_crossentropy',\n",
    "                 metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f24c7bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 100\n",
    "NUM_EPOCH = 50\n",
    "BATCH_SIZE = 2\n",
    "STEPS_PER_EPOCH = TRAIN_SIZE / BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ceab0e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "50/50 [==============================] - 0s 893us/step - loss: 1.2444 - accuracy: 0.3800\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 0s 821us/step - loss: 1.1133 - accuracy: 0.4200\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 0s 866us/step - loss: 1.0304 - accuracy: 0.5700\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 0s 893us/step - loss: 0.9832 - accuracy: 0.6600\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 0s 915us/step - loss: 0.9459 - accuracy: 0.6600\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 0s 838us/step - loss: 0.9066 - accuracy: 0.6700\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 0s 890us/step - loss: 0.8721 - accuracy: 0.6700\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 0s 899us/step - loss: 0.8321 - accuracy: 0.6800\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 0s 874us/step - loss: 0.7931 - accuracy: 0.7100\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 0s 872us/step - loss: 0.7622 - accuracy: 0.7500\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.7349 - accuracy: 0.7100\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 0s 991us/step - loss: 0.7085 - accuracy: 0.7100\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 0s 784us/step - loss: 0.6840 - accuracy: 0.8300\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 0s 855us/step - loss: 0.6594 - accuracy: 0.7500\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 0s 807us/step - loss: 0.6405 - accuracy: 0.7900\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 0s 781us/step - loss: 0.6206 - accuracy: 0.7800\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 0s 848us/step - loss: 0.6047 - accuracy: 0.7700\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 0s 864us/step - loss: 0.5883 - accuracy: 0.8600\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 0s 824us/step - loss: 0.5742 - accuracy: 0.8000\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 0s 798us/step - loss: 0.5578 - accuracy: 0.8900\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 0s 751us/step - loss: 0.5442 - accuracy: 0.8400\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 0s 850us/step - loss: 0.5322 - accuracy: 0.8100\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 0s 819us/step - loss: 0.5211 - accuracy: 0.9000\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 0s 827us/step - loss: 0.5086 - accuracy: 0.8700\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 0s 820us/step - loss: 0.4988 - accuracy: 0.9000\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 0s 993us/step - loss: 0.4910 - accuracy: 0.9500\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 0s 802us/step - loss: 0.4806 - accuracy: 0.9300\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 0s 844us/step - loss: 0.4706 - accuracy: 0.8600\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 0s 828us/step - loss: 0.4641 - accuracy: 0.8900\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 0s 749us/step - loss: 0.4529 - accuracy: 0.9400\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 0s 864us/step - loss: 0.4470 - accuracy: 0.9400\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 0s 900us/step - loss: 0.4392 - accuracy: 0.9600\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 0s 853us/step - loss: 0.4310 - accuracy: 0.9500\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 0s 845us/step - loss: 0.4265 - accuracy: 0.9400\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 0s 816us/step - loss: 0.4192 - accuracy: 0.9400\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 0s 857us/step - loss: 0.4133 - accuracy: 0.9400\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 0s 837us/step - loss: 0.4055 - accuracy: 0.9500\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 0s 819us/step - loss: 0.4014 - accuracy: 0.9500\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 0s 854us/step - loss: 0.3989 - accuracy: 0.9200\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 0s 901us/step - loss: 0.3893 - accuracy: 0.9600\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 0s 814us/step - loss: 0.3812 - accuracy: 0.9500\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 0s 857us/step - loss: 0.3778 - accuracy: 0.9500\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 0s 818us/step - loss: 0.3712 - accuracy: 0.9500\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 0s 847us/step - loss: 0.3643 - accuracy: 0.9500\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 0s 913us/step - loss: 0.3587 - accuracy: 0.9500\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 0s 906us/step - loss: 0.3532 - accuracy: 0.9600\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 0s 875us/step - loss: 0.3487 - accuracy: 0.9600\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 0s 863us/step - loss: 0.3430 - accuracy: 0.9500\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 0s 818us/step - loss: 0.3374 - accuracy: 0.9600\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 0s 852us/step - loss: 0.3324 - accuracy: 0.9600\n"
     ]
    }
   ],
   "source": [
    "ds_train = ds_train.shuffle(TRAIN_SIZE).batch(BATCH_SIZE)\n",
    "history = iris_mlp.fit(ds_train, epochs = NUM_EPOCH, steps_per_epoch = STEPS_PER_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f6c5313e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 124ms/step - loss: 0.2676 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2676054835319519, 1.0]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_mlp.evaluate(ds_test.batch(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1163ea33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
